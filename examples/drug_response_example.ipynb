{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import collections\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pyro\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceGraph_ELBO\n",
    "from pyro.optim import CosineAnnealingWarmRestarts\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as ssp\n",
    "\n",
    "import umap\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.distributions.utils import probs_to_logits\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drvish.util.plot as drplt\n",
    "\n",
    "from drvish.data import split_dataset, split_labeled_dataset\n",
    "from drvish.train import train_until_plateau, evaluate, AggMo, train, evaluate\n",
    "from drvish.util import build_dr_dataset\n",
    "\n",
    "from drvish.models import NBVAE, DRNBVAE\n",
    "\n",
    "from drvish.models.modules import LinearMultiBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 8\n",
    "n_latent = 8\n",
    "n_cells_per_class = 512\n",
    "n_features = 128\n",
    "n_drugs = 2\n",
    "n_conditions = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp, classes, progs, z, doses, drs, lib_size, umis = build_dr_dataset(\n",
    "    n_classes=n_classes,\n",
    "    n_latent=n_latent,\n",
    "    n_cells_per_class=n_cells_per_class,\n",
    "    n_features=n_features,\n",
    "    n_drugs=n_drugs,\n",
    "    n_conditions=n_conditions,\n",
    "    library_kw={'loc': 5.5, 'scale': 0.5},\n",
    "    class_kw={\"scale\": 2.0, \"sparsity\": 0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drplt.make_grid(\n",
    "    *[drplt.drug_response(d.reshape(-1, n_conditions), dos, classes)\n",
    "     for d,dos in zip(drs,doses)],\n",
    "    n_cols=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_umis = umis[:, 4:, :]\n",
    "te_exp = exp[:, 4:, :]\n",
    "te_classes = classes[classes >= 4]\n",
    "te_drs = [d[:, 4:, :] for d in drs]\n",
    "\n",
    "umis = umis[:, :4, :]\n",
    "exp = exp[:, :4, :]\n",
    "classes = classes[classes < 4]\n",
    "drs = [d[:, :4, :] for d in drs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umis_flat = umis.reshape((4 * n_cells_per_class, n_features))\n",
    "\n",
    "dr_means = torch.stack([torch.tensor(ssp.logit(d).mean(0)) for d in drs], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dl, val_dl = split_dataset(\n",
    "    torch.tensor(umis_flat, dtype=torch.float),\n",
    "    batch_size=128,\n",
    "    train_p=0.875,\n",
    ")\n",
    "\n",
    "pyro.clear_param_store()\n",
    "nbvae = NBVAE(\n",
    "    n_input=n_features,\n",
    "    n_latent=16,\n",
    "    layers=[256, 256],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dl, val_dl = split_labeled_dataset(\n",
    "    torch.tensor(umis_flat, dtype=torch.float),\n",
    "    labels=classes,\n",
    "    target=dr_means, \n",
    "    batch_size=128,\n",
    "    train_p=0.875,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "nbvae = DRNBVAE(\n",
    "    n_input=n_features,\n",
    "    n_classes=n_classes - 4,\n",
    "    n_drugs=n_drugs,\n",
    "    n_conditions=n_conditions,\n",
    "    n_latent=16,\n",
    "    layers=[256, 256],\n",
    "    lam_scale=1.0,\n",
    "    bias_scale=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    {\n",
    "        \"optimizer\": AggMo,\n",
    "        \"T_0\": 10,\n",
    "        \"eta_min\": 1e-6,\n",
    "        \"optim_args\": {\"lr\": 5e-4, \"betas\": [0.0, 0.9, 0.99], \"nesterov\": True},\n",
    "    },\n",
    "    {\"clip_norm\": 20.0}\n",
    ")\n",
    "svi = SVI(nbvae.model, nbvae.guide, scheduler, loss=TraceGraph_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, val_loss = train_until_plateau(svi, scheduler, tr_dl, val_dl, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drvish.train import cos_annealing_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caf = lambda e: cos_annealing_factor(e % 10, 10) * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss2, val_loss2 = train_until_plateau(\n",
    "    svi, scheduler, tr_dl, val_dl, verbose=True, min_cycles=5\n",
    ")\n",
    "\n",
    "train_loss.extend(train_loss2)\n",
    "val_loss.extend(val_loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "\n",
    "k = 10\n",
    "\n",
    "x = np.arange(len(train_loss))\n",
    "ax.plot(x[1:], train_loss[1:], label=\"train\")\n",
    "ax.plot(x[1:], val_loss[1:], label=\"validation\")\n",
    "\n",
    "axin = ax.inset_axes([0.2, 0.4, 0.7, 0.3])\n",
    "\n",
    "axin.plot(x[k:], train_loss[k:], label=\"train\")\n",
    "axin.plot(x[k:], val_loss[k:], label=\"validation\")\n",
    "axin.autoscale(tight=True)\n",
    "b = ax.indicate_inset_zoom(axin, label=None)\n",
    "axin.set_xticklabels(\"\")\n",
    "axin.set_yticklabels(\"\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_t = torch.tensor(classes)\n",
    "\n",
    "umis_t = torch.tensor(umis_flat, dtype=torch.float)\n",
    "\n",
    "z_loc, _ = nbvae.encoder(umis_t)\n",
    "\n",
    "mean_dr_logit = nbvae.lmb.calc_response(z_loc, class_t).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_umis_flat = te_umis.reshape(4 * n_cells_per_class, n_features)\n",
    "te_dr_means = np.dstack([ssp.logit(d).mean(0) for d in te_drs])\n",
    "\n",
    "te_umi_t = torch.tensor(te_umis_flat, dtype=torch.float)\n",
    "te_z, _ = nbvae.encoder(te_umi_t)\n",
    "\n",
    "te_mean_dr_logit = nbvae.lmb.calc_response(te_z, class_t).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = umap.UMAP().fit_transform(np.sqrt(umis_flat))\n",
    "x2 = umap.UMAP().fit_transform(z_loc.detach().numpy())\n",
    "\n",
    "te_x = umap.UMAP().fit_transform(np.sqrt(te_umis_flat))\n",
    "te_x2 = umap.UMAP().fit_transform(te_z.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2, 2, figsize=(12, 12))\n",
    "ax[0,0].scatter(x[:,0], x[:,1], c=classes)\n",
    "ax[0,1].scatter(x2[:,0], x2[:,1], c=classes)\n",
    "ax[1,0].scatter(te_x[:,0], te_x[:,1], c=te_classes)\n",
    "ax[1,1].scatter(te_x2[:,0], te_x2[:,1], c=te_classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4, n_drugs, figsize=(12, 20))\n",
    "\n",
    "for i in range(n_drugs):\n",
    "    for j,c in enumerate(np.unique(classes)):\n",
    "        ax[j,i].plot(ssp.expit(dr_means[j,:,i].T), color='b')\n",
    "        ax[j,i].plot(ssp.expit(mean_dr_logit[j,:,i].T), color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4, n_drugs, figsize=(12, 20))\n",
    "\n",
    "for i in range(n_drugs):\n",
    "    for j,c in enumerate(np.unique(classes)):\n",
    "        ax[j,i].plot(ssp.expit(te_dr_means[j,:,i].T), color='b')\n",
    "        ax[j,i].plot(ssp.expit(te_mean_dr_logit[j,:,i].T), color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
